
\section{Convergence Diagnostics}


\subsection{ Gelman-Rubin }

The Gelman-Rubin test is a statistical test that provides a general convergence diagnostic for stationary Markov Chains. 
It is based on comparing intra-chain variance with inter-chain variance and requires generating M independent realisations of the chain from different starting points.


\subsection{ Autocorrelation Test }
The Gelman-Rubin test works well in practice and is based on solid reasoning, but it requires M independent replica of the chain. 
If only a single realization of the chain is available, it cannot be used. 
The (weaker, in terms of statistical power) autocorrelation test can then be used instead. 
It is based on computing the autocorrelation function of the Markov chain, defined as:

\[
	c(\tau) = \frac
		{ \sum_{i = 1}^{N - \tau} (\bm{x}_i - \hat{\bm{\mu}}) (\bm{x}_{i+\tau} - \hat{\bm{\mu}}) }
		{ \sum_{i = 1}^N (\bm{x}_i - \hat{\bm{\mu}})^2 }
\]

where $ \hat{\bm{\mu}} = \frac{1}{N} \sum_{i = 1}^N \bm{x}_i $


\begin{comment}
Hamiltonian dynamics is a framework used in classical mechanics to describe the evolution of physical systems. 
It introduces the concept of a Hamiltonian function, denoted as $H(\bm{x}, \bm{p})$,
\[
	H(\bm{x}, \bm{p}) = U(\bm{x}) + K(\bm{p})
\]
where $\bm{x}$ represents the position vector and $\bm{p}$ the momentum vector and $U$ and $K$ are called the potential and kinetic energy respectively.
Hamiltonian dynamics are governed by the equations:

\[
\begin{aligned}
	\frac{\dif \bm{x}}{\dif t} &= \frac{\partial H}{\partial \bm{p}} \\
	\frac{\dif \bm{p}}{\dif t} &= -\frac{\partial H}{\partial \bm{x}} \\
\end{aligned}
\]

For an EBM Model the potential energy function coincides with $U$, 
and for the kernel of any other density we can do the familiar transformation $U(\bm{x}) = - \log(\tilde{f}(x))$.
The Hamiltonian in its turn can be used as the energy function in a new EBM to define a joint density
\[
	P(\bm{x}, \bm{p}) = \frac{1}{Z} \exp( - H(\bm{x}, \bm{p}) ) = \frac{1}{Z} \exp( - U(\bm{x}) - K(\bm{p}) )
\]


\subsection{Hamiltonian Monte Carlo (HMC)}

HMC is a Metropolis-Hastings sampling algorithm that employs Hamiltonian dynamics to generate new proposal states, 
and in this way guide the exploration of the state space efficiently. 
The simulated dynamics allow the algorithm to explore distant regions in a more coherent and directed manner compared to random-walk-based methods.
Unlike traditional Metropolis Hastings algorithms, that often sample the proposed next state using a multivariate-normal step directly, 
HMC samples a momentum and subsequently uses the deterministic dynamics to simulate a trajectory from the current position to the next proposal state.
Unlike in Langevin Dynamics this trajectory can consist of multiple steps which can boost convergence speed. 

A key component is to negate the momentum variables at the end of one trajectory simulation. 
This guarantees that the proposal distribution $q$ is symmetric which makes it vanish in the Metropolis-Hastings acceptance probability
\[
\begin{aligned}
	\alpha(\bm{x}, \bm{p}; \hat{\bm{x}}, \hat{\bm{p}})
	&= \min \left(1, \frac{P(\hat{\bm{x}}, \hat{\bm{p}}) q(\bm{x}, \bm{p} | \hat{\bm{x}}, \hat{\bm{p}} ) }{P(\bm{x}, \bm{p})} q(\hat{\bm{x}}, \hat{\bm{p}} | \bm{x}, \bm{p} ) \right) \\
	&= \min \left(1, \frac{P(\hat{\bm{x}}, \hat{\bm{p}}) }{P(\bm{x}, \bm{p})} \right) \\
	&= \min \left(1, \frac{P(\hat{\bm{x}}, \hat{\bm{p}}) }{P(\bm{x}, \bm{p})} \right) \\
\end{aligned}
\]

So that it can be expressed purely in terms of the respective Hamiltonians
\[
\begin{aligned}
	\alpha(\bm{x}, \bm{p}; \hat{\bm{x}}, \hat{\bm{p}})
	&= \min \left(1, \frac{P(\hat{\bm{x}}, \hat{\bm{p}}) }{P(\bm{x}, \bm{p})} \right) \\
	&= \min \left(1, \frac{ \exp( - H(\hat{\bm{x}}, \hat{\bm{p}}) ) }{ \exp( - H(\bm{x}, \bm{p}) ) } \right) \\
	&= \min \left(1, \exp( H(\bm{x}, \bm{p}) - H(\hat{\bm{x}}, \hat{\bm{p}}) ) \right) \\
\end{aligned}
\]

HMC's ability to use gradient information and simulate deterministic dynamics makes it a powerful tool for efficient exploration of complex, high-dimensional parameter spaces.



Set with the parameters
\begin{enumerate}
	\item Desired number of samples: $N$
	\item Number of leapfrog steps: $L$
	\item Step size for leapfrog integration: $\varepsilon$
	\item Mass matrix for kinetic energy: $\bm{M}$
\end{enumerate}

and with concrete kinetic energy function $K(\bm{p}) = \frac{ \bm{p}^T M \bm{p} }{2}$



\NoCaptionOfAlgo
\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon
\SetKwComment{Comment}{$\triangleright$\ }{}
\SetAlCapSkip{1em}
\SetAlCapNameFnt{\normalfont\normalsize}
\caption{Hamiltonian Monte Carlo Algorithm $(N, L, \varepsilon, \bm{M})$}

Initialise: 
$\bm{x}_0$ \;
$ \bm{p}_0 \sim \mathcal{N}(0, \bm{M}) $ \;

\For{$ i \leq N $ }{

	$ \hat{\bm{x}} = \bm{x}_i $ \;
	
	sample Momentum:
	$ \hat{\bm{p}} \sim \mathcal{N}(0, \bm{M}) $ \;
	
	% Make a half step for momentum at the beginning
	$ \hat{\bm{p}} = \hat{\bm{p}} - \varepsilon \frac{\nabla U(\hat{\bm{x}})}{2} $ \;
	
	leapfrog Integration:\\
	\For{$ k \leq L-1 $ }{
		$\hat{\bm{x}} = \hat{\bm{x}} + \varepsilon \hat{\bm{p}}$\;
		$\hat{\bm{p}} = \hat{\bm{p}} - \varepsilon \nabla U(\hat{\bm{x}})$\;
	}
	%missing full step for position
	$\hat{\bm{x}} = \hat{\bm{x}} + \varepsilon \hat{\bm{p}}$\;
	
	%Make a half step for momentum at the end
	$ \hat{\bm{p}} = \hat{\bm{p}} - \varepsilon \frac{\nabla U(\hat{\bm{x}})}{2} $ \;
	
	negate Momentum:
	$\hat{\bm{p}} = - \hat{\bm{p}}$ \;
	
	evaluate Hamiltonian for the current point: 
	$H(\bm{x}_i, \bm{p}_i) = U(\bm{x}_i) + K(\bm{p}_i)$ \;
	
	evaluate Hamiltonian for the proposed point:
	$H(\hat{\bm{x}}, \hat{\bm{p}} ) = U(\hat{\bm{x}}) + K(\hat{\bm{p}})$ \;
	
	compute 
	$
		\alpha \left( (\bm{x}_i, \bm{p}_i), (\hat{\bm{x}}, \hat{\bm{p}}) \right) 
		= \min \left \{ 1, \exp ( H(\bm{x}_i, \bm{p}_i) - H( \hat{\bm{x}}, \hat{\bm{p}} ) ) \right \}
	$
	\;
	sample $u \sim \mathcal{U}(0,1)$ \;
	\uIf{$ u \leq \alpha \left( (\bm{x}_i, \bm{p}_i), (\hat{\bm{x}}, \hat{\bm{p}}) \right)$}{
		$\bm{x}_{i+1} := \hat{\bm{x}}$ \;
	}
	\Else{
		$\bm{x}_{i+1} := \bm{x}_i$ \;
	}
}

\end{algorithm}




\end{comment}





















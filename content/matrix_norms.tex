
\section{Matrix Norms}

===Matrix norms induced by vector p-norms===
If the [[Vector norm#p-norm|''p''-norm for vectors]] (<math>1 \leq p \leq \infty</math>) is used for both spaces <math>K^n</math> and <math>K^m,</math> then the corresponding operator norm is:<ref name=":1" />
<math display="block"> \|A\|_p = \sup_{x \ne 0} \frac{\| A x\| _p}{\|x\|_p}. </math>

These induced norms are different from the [[#"Entrywise" matrix norms|"entry-wise"]] ''p''-norms and the [[Schatten norm|Schatten ''p''-norms]] for matrices treated below, which are also usually denoted by <math> \|A\|_p .</math>

In the special cases of <math>p = 1, \infty,</math> the induced matrix norms can be computed or estimated by
<math display="block"> \|A\|_1 = \max_{1 \leq j \leq n} \sum_{i=1}^m | a_{ij} |, </math>
which is simply the maximum absolute column sum of the matrix;
<math display="block"> \|A\|_\infty = \max_{1 \leq i \leq m} \sum _{j=1}^n | a_{ij} |, </math>
which is simply the maximum absolute row sum of the matrix.

For example, for
<math display="block">A = \begin{bmatrix} -3 & 5 & 7 \\ 2 & 6 & 4 \\ 0 & 2 & 8 \\ \end{bmatrix},</math>
we have that
<math display="block">\|A\|_1 = \max(|{-3}|+2+0; 5+6+2; 7+4+8) = \max(5,13,19) = 19,</math>
<math display="block">\|A\|_\infty = \max(|{-3}|+5+7; 2+6+4;0+2+8) = \max(15,12,10) = 15.</math>

{{anchor|Spectral norm}}
In the special case of <math>p = 2</math> (the [[Euclidean norm]] or <math>\ell_2</math>-norm for vectors), the induced matrix norm is the ''spectral norm''.  (The two values do ''not'' coincide in infinite dimensions &mdash; see [[Spectral radius]] for further discussion.)  The spectral norm of a matrix <math>A</math> is the largest [[singular value]] of <math>A</math> (i.e., the square root of the largest [[eigenvalue]] of the matrix <math>A^*A,</math> where <math>A^*</math> denotes the [[conjugate transpose]] of <math>A</math>):<ref>Carl D. Meyer, Matrix Analysis and Applied Linear Algebra, §5.2, p.281, Society for Industrial & Applied Mathematics, June 2000.</ref>
<math display="block"> \|A\|_2 = \sqrt{\lambda_{\max}\left(A^* A\right)} = \sigma_{\max}(A).</math>
where <math>\sigma_{\max}(A)</math> represents the largest singular value of matrix <math>A.</math> Also,
<math display="block"> \| A^* A\|_2 = \| A A^* \|_2 = \|A\|_2^2</math>
since <math>\| A^* A\|_2 = \sigma_{\max}(A^*A) = \sigma_{\max}(A)^2 = \|A\|^2_2</math> and similarly <math>\|AA^*\|_2 = \|A\|^2_2</math> by [[singular value decomposition]] (SVD). There is another important inequality:
<math display="block"> \|A\| _2 = \sigma_{\max}(A) \leq \|A\|_{\rm F} = \left(\sum_{i=1}^m \sum_{j=1}^n |a_{ij}|^2\right)^{\frac{1}{2}} = \left(\sum_{k=1}^{\min(m,n)} \sigma_{k}^2\right)^{\frac{1}{2}},</math>
where <math>\|A\|_\textrm{F}</math> is the [[#Frobenius norm|Frobenius norm]]. Equality holds if and only if the matrix <math>A</math> is a rank-one matrix or a zero matrix. This inequality can be derived from the fact that the trace of a matrix is equal to the sum of its eigenvalues.

When <math>p=2</math> we have an equivalent definition for <math>\|A\|_2</math> as <math display="block">\sup\{x^* A y : x \in K^m, y \in K^n \text{ with }\|x\|_2 = \|y\|_2 = 1\}.</math> It can be shown to be equivalent to the above definitions using the [[Cauchy–Schwarz inequality]].

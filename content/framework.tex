
\section{Results / Assessment}

As the MC estimates, used to approximate the gradient of the likelihood are based on random samples of the model distribution and the data distribution respectively,
are themselves random variables, the entire estimation process is stochastic in nature and we can view it as a stochastic process.
While there is a lot of theory developed for stochastic processes, 
the complexity contributed by the components of the learning procedure makes it very hard to derive the parameter process analytically.
Even assuming that the samplers for the model provide bona fide samples of the model distribution, 
the randomness of the model samples and of the batch selection comes in in the form of gradients of the likelihood.
It is then warped by the optimisation procedure, which could itself be stochastic algorithm.

Hence there are a lot of dependencies and the evaluation here is empirical and, due to the vast space of hyper parameters and potential choices in strategy,
necessarily not comprehensive.


\subsection{Procedure}

Since the sequence of parameter estimates at every iteration is essentially a realisation of this stochastic process, the error metrics can be viewed as one as well.
Suppose for an experiment a full training procedure is conducted with a total number of $n$ iterations across epochs.
Because of the stochastic nature of the training we repeat the training procedure $m$ times, with the same hyper parameters, 
to get an impression of the parameter estimation process as a whole.
For any error metric $M$ we then obtain a set of $m$ time series of length $n$ and can write $M_i (j)$ for the value of the metric for training run $i$ at iteration $j$.

Now back to the idea, suppose I want to plot two types of graphs for these time series. One where we simply plot the parameter error of the different runs versus time or number of iterations. That plot would have $m$ lines, one for each training run. Next to that plot I would like to add one where I average the error over iterations, i.e. $mean_j = \sum_{i = 1}^m e_i(j)$ where $e_i(j)$ would be the error of the $i$th run at iteration $j$, and also a standard deviation, calculated in a similar way, that I would show as a grey belt around the mean (for these two types of plot I actually already have functions, but not hook classes). Now I change the set of hyperparameters (e.g. change the learning rate or the sampler) and run the experiment again for $n$ iterations and $m$ training runs. Then the I would put the same plot type as before below the previous one in the plot matrix with corresponding annotations for what changed.